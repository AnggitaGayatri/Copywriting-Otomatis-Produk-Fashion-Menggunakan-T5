{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnggitaGayatri/Copywriting-Otomatis-Produk-Fashion-Menggunakan-T5/blob/Anggita-dev/Keywords%20Extraction%20Using%20TF%20IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KEYWORDS EXTRACTION"
      ],
      "metadata": {
        "id": "D4H-mHlwpEnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4PE3xpHdAf-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SpUKQpJ9fPfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd4585b6-6af1-4457-9bd3-0981ce86df15"
      },
      "cell_type": "code",
      "source": [
        "import re, os, string\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-learn importings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4xONUnG-j-",
        "outputId": "97e87b5c-daef-4ceb-9f86-af11d7248ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords # Import the stopwords object\n",
        "\n",
        "stop_words = stopwords.words('indonesian')"
      ],
      "metadata": {
        "id": "cXXfTaApGqKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7XHkjJVfPfr"
      },
      "cell_type": "markdown",
      "source": [
        "### Reading data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"DataMatahari_cleaned.xlsx\"\n",
        "data = pd.read_excel(DATASET_PATH)"
      ],
      "metadata": {
        "id": "fQ7aX0xQFISc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpora = data['cleaned_description'].to_list()"
      ],
      "metadata": {
        "id": "S99P-CgsFphu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-FGL7sfhfPft"
      },
      "cell_type": "markdown",
      "source": [
        "### Keywords Extraction using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_K_KEYWORDS = 5"
      ],
      "metadata": {
        "id": "IOBKKbIRF4v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpora = data['cleaned_description'].to_list()"
      ],
      "metadata": {
        "id": "srFm4ASHF42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('indonesian')"
      ],
      "metadata": {
        "id": "lpcZRSr3F42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "w1coF7pfF43A"
      },
      "cell_type": "code",
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    \"\"\"Sort a dict with highest score\"\"\"\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "\n",
        "\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "    for idx, score in sorted_items:\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ONoId-4zF43A"
      },
      "cell_type": "code",
      "source": [
        "def get_keywords(vectorizer, feature_names, doc):\n",
        "    \"\"\"Return top k keywords from a doc using TF-IDF method\"\"\"\n",
        "\n",
        "    tf_idf_vector = vectorizer.transform([doc])\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,TOP_K_KEYWORDS)\n",
        "\n",
        "    return list(keywords.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-dKexktsfPft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91dfdc30-2ad4-4f03-840c-7a58d80e3c45"
      },
      "cell_type": "code",
      "source": [
        "corpora = [str(x) if not pd.isnull(x) else \"\" for x in corpora]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words, smooth_idf=True, use_idf=True)\n",
        "\n",
        "\n",
        "vectorizer.fit_transform(corpora[5::])\n",
        "\n",
        "# Storing vocab\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hJ2hCgJ8fPft"
      },
      "cell_type": "markdown",
      "source": [
        "### Result"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "EyqpuIPVfPft"
      },
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for doc in corpora:\n",
        "    df = {}\n",
        "    df['deskripsi'] = doc\n",
        "    df['keywords'] = \", \".join(get_keywords(vectorizer, feature_names, doc))\n",
        "    result.append(df)\n",
        "\n",
        "final = pd.DataFrame(result)\n",
        "\n",
        "\n",
        "final.to_csv('data_matahari_tfidf.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv('data_matahari_tfidf.csv')"
      ],
      "metadata": {
        "id": "_o_lHzzmrl3A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}